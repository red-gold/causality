{"version":3,"sources":["webpack://@causalNet/preprocessing/webpack/universalModuleDefinition","webpack://@causalNet/preprocessing/webpack/bootstrap","webpack://@causalNet/preprocessing/external \"causal-net.core\"","webpack://@causalNet/preprocessing/external \"causal-net.utils\"","webpack://@causalNet/preprocessing/external \"causal-net.storage\"","webpack://@causalNet/preprocessing/external \"causal-net.log\"","webpack://@causalNet/preprocessing/./src/causalNetPreprocessingStream.js","webpack://@causalNet/preprocessing/./src/preprocessing.mixins.js","webpack://@causalNet/preprocessing/./src/Image/colorTransforming.mixins.js","webpack://@causalNet/preprocessing/./src/Image/imageSplitting.mixins.js","webpack://@causalNet/preprocessing/./src/imagePreprocessing.js","webpack://@causalNet/preprocessing/./src/NLP/tokenTransforming.mixins.js","webpack://@causalNet/preprocessing/./src/nlpPreprocessing.js","webpack://@causalNet/preprocessing/./src/tabularPreprocessing.js","webpack://@causalNet/preprocessing/./src/tokenizer.en.js","webpack://@causalNet/preprocessing/./src/index.js"],"names":["root","factory","exports","module","require","define","amd","this","__WEBPACK_EXTERNAL_MODULE__0__","__WEBPACK_EXTERNAL_MODULE__1__","__WEBPACK_EXTERNAL_MODULE__2__","__WEBPACK_EXTERNAL_MODULE__3__","installedModules","__webpack_require__","moduleId","i","l","modules","call","m","c","d","name","getter","o","Object","defineProperty","enumerable","get","r","Symbol","toStringTag","value","t","mode","__esModule","ns","create","key","bind","n","object","property","prototype","hasOwnProperty","p","s","functor","Functor","causalNetPreprocessingStream","platform","mixWith","Event","StorageMixins","constructor","preprocessingStorage","logger","super","Storage","F","preprocessingData","samples","labels","finished","trainSet","testSet","PreprocessingData","TrainSet","TestSet","SampleTransformer","sampleFn","LabelTransformer","labelFn","Error","DataHandler","dataHandler","setDataHandler","data","Promise","async","resolve","reject","chunkName","ChunkName","undefined","Sample","identity","idx","sample","enumerate","setItem","JSON","stringify","push","Label","label","on","splitDataset","trainSize","R","CoreFunctor","zip","parseInt","length","splitAt","makeBatchGenerator","batchData","nextIndex","next","samplePath","labelPath","sampleItem","getItem","labelItem","parse","[object Object]","iterator","TrainDataGenerator","batchSize","splitEvery","TestDataGenerator","indexDBStorage","termLogger","PreprocessingMixins","BasePipelineClass","Preprocessing","streamPreprocessing","setByConfig","pipelineConfig","Dataset","Logger","groupBegin","DataSource","groupEnd","ColorTransformingMixins","PreprocessingClass","colorTransform","tranformFn","sampleBuffer","channelSize","flatten","map","blackWhiteTransform","pixel","ImageSplittingMixins","imageSplit","splitSize","imagePreprocessing","BaseFunctor","TokenTransformingMixins","tokenize","sentence","tokenizer","badWordsFilter","tokens","badWordList","filter","token","not","find","equals","wordFreqCount","freqCount","reduce","wordDuplicateRemove","uniq","nlpPreprocessing","connect","configLink","Tokenizer","tabularPreprocessing","tokenizer_en","configureLink","console","log","text","split","__webpack_exports__","preprocessing_mixins"],"mappings":"CAAA,SAAAA,EAAAC,GACA,iBAAAC,SAAA,iBAAAC,OACAA,OAAAD,QAAAD,EAAAG,QAAA,mBAAAA,QAAA,oBAAAA,QAAA,sBAAAA,QAAA,mBACA,mBAAAC,eAAAC,IACAD,OAAA,6EAAAJ,GACA,iBAAAC,QACAA,QAAA,4BAAAD,EAAAG,QAAA,mBAAAA,QAAA,oBAAAA,QAAA,sBAAAA,QAAA,mBAEAJ,EAAA,4BAAAC,EAAAD,EAAA,mBAAAA,EAAA,oBAAAA,EAAA,sBAAAA,EAAA,mBARA,CASCO,KAAA,SAAAC,EAAAC,EAAAC,EAAAC,GACD,mBCTA,IAAAC,EAAA,GAGA,SAAAC,EAAAC,GAGA,GAAAF,EAAAE,GACA,OAAAF,EAAAE,GAAAZ,QAGA,IAAAC,EAAAS,EAAAE,GAAA,CACAC,EAAAD,EACAE,GAAA,EACAd,QAAA,IAUA,OANAe,EAAAH,GAAAI,KAAAf,EAAAD,QAAAC,IAAAD,QAAAW,GAGAV,EAAAa,GAAA,EAGAb,EAAAD,QA0DA,OArDAW,EAAAM,EAAAF,EAGAJ,EAAAO,EAAAR,EAGAC,EAAAQ,EAAA,SAAAnB,EAAAoB,EAAAC,GACAV,EAAAW,EAAAtB,EAAAoB,IACAG,OAAAC,eAAAxB,EAAAoB,EAAA,CAA0CK,YAAA,EAAAC,IAAAL,KAK1CV,EAAAgB,EAAA,SAAA3B,GACA,oBAAA4B,eAAAC,aACAN,OAAAC,eAAAxB,EAAA4B,OAAAC,YAAA,CAAwDC,MAAA,WAExDP,OAAAC,eAAAxB,EAAA,cAAiD8B,OAAA,KAQjDnB,EAAAoB,EAAA,SAAAD,EAAAE,GAEA,GADA,EAAAA,IAAAF,EAAAnB,EAAAmB,IACA,EAAAE,EAAA,OAAAF,EACA,KAAAE,GAAA,iBAAAF,QAAAG,WAAA,OAAAH,EACA,IAAAI,EAAAX,OAAAY,OAAA,MAGA,GAFAxB,EAAAgB,EAAAO,GACAX,OAAAC,eAAAU,EAAA,WAAyCT,YAAA,EAAAK,UACzC,EAAAE,GAAA,iBAAAF,EAAA,QAAAM,KAAAN,EAAAnB,EAAAQ,EAAAe,EAAAE,EAAA,SAAAA,GAAgH,OAAAN,EAAAM,IAAqBC,KAAA,KAAAD,IACrI,OAAAF,GAIAvB,EAAA2B,EAAA,SAAArC,GACA,IAAAoB,EAAApB,KAAAgC,WACA,WAA2B,OAAAhC,EAAA,SAC3B,WAAiC,OAAAA,GAEjC,OADAU,EAAAQ,EAAAE,EAAA,IAAAA,GACAA,GAIAV,EAAAW,EAAA,SAAAiB,EAAAC,GAAsD,OAAAjB,OAAAkB,UAAAC,eAAA1B,KAAAuB,EAAAC,IAGtD7B,EAAAgC,EAAA,GAIAhC,IAAAiC,EAAA,mBClFA3C,EAAAD,QAAAM,iBCAAL,EAAAD,QAAAO,iBCAAN,EAAAD,QAAAQ,iBCAAP,EAAAD,QAAAS,uFCoJA,IAAIoC,EAAU,IAAIC,UACHC,EAAA,IAjJf,cAA2CC,WAASC,QAAQC,QACxD,CAAEC,mBACFC,YAAYC,EAAsBR,EAASS,GACvCC,QACAlD,KAAKmD,QAAUH,EACfhD,KAAKoD,EAAIZ,EACTxC,KAAKiD,OAASA,EACdjD,KAAKqD,kBAAoB,CAAEC,QAAS,GAAIC,OAAQ,GAAIC,UAAU,EAAOC,SAAU,GAAIC,QAAS,IAEhGC,wBACI,OAAO3D,KAAKqD,kBAGhBO,eACI,OAAO5D,KAAKqD,kBAAkBI,SAGlCI,cACI,OAAO7D,KAAKqD,kBAAkBK,QAGlCI,sBAAsBC,GAClB/D,KAAK+D,SAAWA,EAEpBC,qBAAqBC,GACjBjE,KAAKiE,QAAUA,EAEnBH,wBACI,IAAI9D,KAAK+D,SACL,MAAMG,MAAM,gCAEhB,OAAOlE,KAAK+D,SAEhBC,uBACI,IAAIhE,KAAKiE,QACL,MAAMC,MAAM,+BAEhB,OAAOlE,KAAKiE,QAEhBE,kBACI,IAAInE,KAAKoE,YACL,MAAMF,MAAM,0BAEhBlE,KAAKoE,YAGTC,iBACI,MAEMP,EAAoB9D,KAAK8D,kBACzBE,EAAmBhE,KAAKgE,iBACxBb,EAAUnD,KAAKmD,QACrBnD,KAAKoE,YAAeE,IACT,IAAIC,QAAQC,MAAOC,EAASC,KAC/B,IAAIC,EAAYL,EAAKM,UAIrB,QAHiBC,IAAdF,GACCD,EAAQ,4BAETJ,EAAKQ,OAAO,CACX,IAAIxB,EAAUQ,EAAkBQ,EAAKQ,QACjCC,EAAW,GACf,IAAI,IAAKC,EAAKC,KAAWjF,KAAKoD,EAAE8B,UAAU5B,GACtCyB,EAAWJ,EAAY,IAAMK,QACvB7B,EAAQgC,QAAQ,wBAA0BJ,EAAUK,KAAKC,UAAUJ,IACzEjF,KAAKqD,kBAAkBC,QAAQgC,KAAKP,GAI5C,GAAGT,EAAKiB,MAAM,CACV,IAAIhC,EAASS,EAAiBM,EAAKiB,OAC/BR,EAAW,GACf,IAAI,IAAKC,EAAKQ,KAAUxF,KAAKoD,EAAE8B,UAAU3B,GACrCwB,EAAWJ,EAAY,IAAMK,QACvB7B,EAAQgC,QAAQ,uBAAyBJ,EAAUK,KAAKC,UAAUG,IACxExF,KAAKqD,kBAAkBE,OAAO+B,KAAKP,GAG3CN,GAAQ,MAGhBzE,KAAKyF,GAAG,OAAQzF,KAAKoE,aAGzBsB,aAAaC,EAAU,IACnB,MAAMC,EAAI5F,KAAKoD,EAAEyC,YAEjB,IAAIvC,QAAEA,EAAFC,OAAWA,GAAWvD,KAAKqD,kBAC3BiB,EAAOtE,KAAKoD,EAAE0C,IAAIxC,EAASC,GAC5BoC,EAAY,IACXA,EAAYI,SAAqB,GAAZzB,EAAK0B,SAE9B,MAAQvC,EAAUC,GAAYkC,EAAEK,QAAQN,EAAWrB,GAGnD,OAFAtE,KAAKqD,kBAAkBI,SAAWA,EAClCzD,KAAKqD,kBAAkBK,QAAUA,EAC1B,CAACD,EAAUC,GAEtBwC,mBAAmBC,GACf,MAAMhD,EAAUnD,KAAKmD,QACrB,IAAIiD,EAAY,EAuBhB,MAtBuB,CACfC,KAAM7B,UACF,IAAIlB,EAAU,GAAIC,EAAS,GAE3B,IAAI,IAAK+C,EAAYC,KAAcJ,EAAUC,GAAW,CACpDE,EAAa,wBAA0BA,EACvCC,EAAY,uBAAyBA,EACrC,IAAIC,QAAmBrD,EAAQsD,QAAQH,GACnCI,QAAkBvD,EAAQsD,QAAQF,GACtCjD,EAAU,IAAIA,EAAS8B,KAAKuB,MAAMH,EAAWF,KAC7C/C,EAAS,IAAIA,EAAQ6B,KAAKuB,MAAMD,EAAUH,KAI9C,OAFAH,GAAa,EAEN,CAAE9C,UAASC,WAEtBqD,EAAErF,OAAOsF,YACL,KAAMT,EAAYD,EAAUH,cAClBhG,KAAKqG,SAM/BS,yBACI,MAAMlD,EAAW5D,KAAK4D,SAChBgC,EAAI5F,KAAKoD,EAAEyC,YACjB,OAAQkB,IAEJ,IAAIZ,EAAYP,EAAEoB,WAAWD,EAAWnD,GAExC,OAAO5D,KAAKkG,mBAAmBC,IAIvCc,wBACI,MAAMpD,EAAU7D,KAAK6D,QACf+B,EAAI5F,KAAKoD,EAAEyC,YACjB,OAAQkB,IAEJ,IAAIZ,EAAYP,EAAEoB,WAAWD,EAAWlD,GACxC,OAAO7D,KAAKkG,mBAAmBC,MAKKe,iBAAgB1E,EAAS2E,cCnH1DC,MAlCcC,IAAsB,cAAcA,EAE7DC,oBACI,IAAKtH,KAAKuH,oBACN,MAAMrD,MAAM,kCAEhB,OAAOlE,KAAKuH,oBAGhBD,kBAAkBC,GACdvH,KAAKuH,oBAAsBA,EAK/BC,YAAYC,GACLvE,MAAMsE,aACLtE,MAAMsE,YAAYC,GAEtB,MAAMH,cAAEA,GAAkBG,EAAeC,QAEzC,GADA1H,KAAK2H,OAAOC,WAAW,iBACpB5H,KAAK6H,YAAcP,EAAc,CAChC,MAAMxD,kBAAEA,EAAFE,iBAAqBA,GAAqBsD,EAChDtH,KAAKsH,cAAcxD,kBAAoBA,EACvC9D,KAAKsH,cAActD,iBAAmBA,EACtChE,KAAKsH,cAAcjD,iBACnBoD,EAAeX,mBAAqB9G,KAAKsH,cAAcR,mBACvDW,EAAeR,kBAAoBjH,KAAKsH,cAAcL,kBAG1D,OADAjH,KAAK2H,OAAOG,WACLL,KCTAM,MArBkBC,IAAuB,cAAcA,EAElEC,eAAeC,EAAYC,EAAcC,GACrC,MAAMxC,EAAI5F,KAAK4F,EACf,OAAOA,EAAEyC,QAAQzC,EAAE0C,IAAIJ,EAAYtC,EAAEoB,WAAWoB,EAAaD,KAQjEI,oBAAoBJ,EAAcC,GAK9B,OAAOpI,KAAKiI,eAJUO,OACAA,EAAM,GAAKA,EAAM,GAAIA,EAAM,IAAI,GAGZL,EAAcC,MCLhDK,MAZeT,IAAuB,cAAcA,EAO/DU,WAAWP,EAAcQ,GACrB,OAAO3I,KAAK4F,EAAEoB,WAAW2B,EAAWR,MCc7B,IAAAS,EAAA,IARf,cAAiCjG,WAASC,QAAQiG,UAAa,CACvDd,EACAU,KACJ1F,cACIG,UC+BO4F,MAjDkBd,IAAuB,cAAcA,EAMlEe,SAASC,GAEL,OADUhJ,KAAK4F,EAAe5F,KAAKiJ,UAClBF,SAASC,GAQ9BE,eAAeC,EAAQC,GACnB,MAAMxD,EAAI5F,KAAK4F,EACf,OAAOA,EAAEyD,OAAQC,GAAQ1D,EAAE2D,IAAI3D,EAAE4D,KAAK5D,EAAE6D,OAAOH,GAAhB1D,CAAwBwD,IAAeD,GAQ1EO,cAAcP,EAAQQ,EAAU,IAW5B,OAVU3J,KAAK4F,EAUNgE,OATU,CAACD,EAAWL,UACHzE,IAArB8E,EAAUL,GACTK,EAAUL,GAAS,EAGnBK,EAAUL,IAAU,EAEjBK,GAEiBA,EAAWR,GAO3CU,oBAAoBV,GAEhB,OADUnJ,KAAK4F,EACNkE,KAAKX,MCCP,IAAAY,EAAA,IAlCf,cAA+BpH,WAASC,QAAQiG,UAC5C,CAAEC,KACF/F,cACIG,QAOJ8G,QAAQC,GACJjK,KAAKiJ,UAAUe,QAAQC,GAO3BC,gBACI,IAAIlK,KAAKiJ,UACL,MAAM/E,MAAM,wBAEhB,OAAOlE,KAAKiJ,UAOhBiB,cAAcjB,GACVjJ,KAAKiJ,UAAYA,SCjCV,IAAAkB,EAAA,IAPf,cAAmCxH,WAASC,QAAQiG,UAChD,KACA9F,cACIG,UCWO,IAAAkH,EAAA,IAXf,MACIrH,eAEAiH,QAAQK,GACJC,QAAQC,IAAI,gEAEhBxB,SAASyB,GAEL,OAAOA,EAAKC,MADD,gCACWpB,OAAOC,GAAe,KAARA,KCd5ChJ,EAAAQ,EAAA4J,EAAA,iDAAAhI,IAAApC,EAAAQ,EAAA4J,EAAA,wCAAAC,IAAArK,EAAAQ,EAAA4J,EAAA,uCAAA9B,IAAAtI,EAAAQ,EAAA4J,EAAA,qCAAAX,IAAAzJ,EAAAQ,EAAA4J,EAAA,yCAAAP,IAAA7J,EAAAQ,EAAA4J,EAAA,gCAAAN","file":"@causalNet/preprocessing.web.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory(require(\"causal-net.core\"), require(\"causal-net.utils\"), require(\"causal-net.storage\"), require(\"causal-net.log\"));\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([\"causal-net.core\", \"causal-net.utils\", \"causal-net.storage\", \"causal-net.log\"], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"@causalNet/preprocessing\"] = factory(require(\"causal-net.core\"), require(\"causal-net.utils\"), require(\"causal-net.storage\"), require(\"causal-net.log\"));\n\telse\n\t\troot[\"@causalNet/preprocessing\"] = factory(root[\"causal-net.core\"], root[\"causal-net.utils\"], root[\"causal-net.storage\"], root[\"causal-net.log\"]);\n})(this, function(__WEBPACK_EXTERNAL_MODULE__0__, __WEBPACK_EXTERNAL_MODULE__1__, __WEBPACK_EXTERNAL_MODULE__2__, __WEBPACK_EXTERNAL_MODULE__3__) {\nreturn "," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 5);\n","module.exports = __WEBPACK_EXTERNAL_MODULE__0__;","module.exports = __WEBPACK_EXTERNAL_MODULE__1__;","module.exports = __WEBPACK_EXTERNAL_MODULE__2__;","module.exports = __WEBPACK_EXTERNAL_MODULE__3__;","import { Event, Functor } from 'causal-net.core';\nimport { platform } from 'causal-net.utils';\nimport { indexDBStorage, StorageMixins } from 'causal-net.storage';\nimport { termLogger } from 'causal-net.log';\nclass CausalNetPreprocessingStream extends platform.mixWith(Event, \n    [ StorageMixins ]){\n    constructor(preprocessingStorage, functor, logger){\n        super();\n        this.Storage = preprocessingStorage;\n        this.F = functor;\n        this.logger = logger;\n        this.preprocessingData = { samples: [], labels: [], finished: false, trainSet: [], testSet: [] };  \n    }\n    get PreprocessingData(){\n        return this.preprocessingData;\n    }\n\n    get TrainSet(){\n        return this.preprocessingData.trainSet;\n    }\n\n    get TestSet(){\n        return this.preprocessingData.testSet;\n    }\n    \n    set SampleTransformer(sampleFn){\n        this.sampleFn = sampleFn;\n    }\n    set LabelTransformer(labelFn){\n        this.labelFn = labelFn;\n    }\n    get SampleTransformer(){\n        if(!this.sampleFn){\n            throw Error('SampleTransformer is not set');\n        }\n        return this.sampleFn;\n    }\n    get LabelTransformer(){\n        if(!this.labelFn){\n            throw Error('LabelTransformer is not set');\n        }\n        return this.labelFn;\n    }\n    get DataHandler(){\n        if(!this.dataHandler){\n            throw Error('DataHandler is not set');\n        }\n        this.dataHandler;\n    }\n\n    setDataHandler(){\n        const Enumerate = (val)=>this.F.enumerate(val);\n        // console.log(Enumerate([0,2,4]));//TODO: fix this failure\n        const SampleTransformer = this.SampleTransformer;\n        const LabelTransformer = this.LabelTransformer;\n        const Storage = this.Storage;\n        this.dataHandler = (data)=>{\n            return new Promise(async (resolve, reject)=>{\n                let chunkName = data.ChunkName;\n                if(chunkName === undefined){\n                    reject(`chunkName is not defined`);\n                }\n                if(data.Sample){\n                    let samples = SampleTransformer(data.Sample);\n                    let identity = '';\n                    for(let [idx, sample] of this.F.enumerate(samples)){\n                        identity = chunkName + '/' + idx;\n                        await Storage.setItem('preprocessing/sample/' + identity, JSON.stringify(sample));\n                        this.preprocessingData.samples.push(identity);\n                        \n                    }\n                }\n                if(data.Label){\n                    let labels = LabelTransformer(data.Label);\n                    let identity = '';\n                    for(let [idx, label] of this.F.enumerate(labels)){\n                        identity = chunkName + '/' + idx;\n                        await Storage.setItem('preprocessing/label/' + identity, JSON.stringify(label));\n                        this.preprocessingData.labels.push(identity);\n                    }\n                }\n                resolve(true);\n            }); \n        };\n        this.on('data', this.dataHandler);\n    }\n    \n    splitDataset(trainSize=0.9){\n        const R = this.F.CoreFunctor;\n        //TODO: enhance this for handle missing data/label case\n        let { samples, labels } = this.preprocessingData;\n        let data = this.F.zip(samples, labels);\n        if(trainSize < 1){\n            trainSize = parseInt(data.length*0.9);\n        }    \n        const [ trainSet, testSet ] = R.splitAt(trainSize, data);\n        this.preprocessingData.trainSet = trainSet;\n        this.preprocessingData.testSet = testSet;\n        return [trainSet, testSet];\n    }\n    makeBatchGenerator(batchData){\n        const Storage = this.Storage;\n        let nextIndex = 0;\n        const batchGenerator = {\n                next: async()=>{\n                    let samples = [], labels = [];\n                    \n                    for(let [samplePath, labelPath] of batchData[nextIndex]){\n                        samplePath = 'preprocessing/sample/' + samplePath;\n                        labelPath = 'preprocessing/label/' + labelPath;\n                        let sampleItem = await Storage.getItem(samplePath);\n                        let labelItem = await Storage.getItem(labelPath);\n                        samples = [...samples, JSON.parse(sampleItem[samplePath])];\n                        labels = [...labels, JSON.parse(labelItem[labelPath])];\n                    }\n                    nextIndex += 1;\n                    \n                    return { samples, labels };\n                },\n                *[Symbol.iterator]() {\n                    while(nextIndex < batchData.length){\n                        yield this.next();\n                    }\n                }\n            };\n        return batchGenerator;\n    }\n    get TrainDataGenerator(){\n        const TrainSet = this.TrainSet;\n        const R = this.F.CoreFunctor;\n        return (batchSize)=>{\n            //TODO: perform permutate\n            let batchData = R.splitEvery(batchSize, TrainSet);\n            \n            return this.makeBatchGenerator(batchData);\n        };\n        \n    }\n    get TestDataGenerator(){\n        const TestSet = this.TestSet;\n        const R = this.F.CoreFunctor;\n        return (batchSize)=>{\n            //TODO: perform permutate\n            let batchData = R.splitEvery(batchSize, TestSet);\n            return this.makeBatchGenerator(batchData);\n        };\n    }\n}\nvar functor = new Functor();\nexport default new CausalNetPreprocessingStream(indexDBStorage, functor, termLogger);","const PreprocessingMixins = (BasePipelineClass) => class extends BasePipelineClass{\n    \n    get Preprocessing(){\n        if( !this.streamPreprocessing ){\n            throw Error('streamPreprocessing is not set');\n        }\n        return this.streamPreprocessing;\n    }\n\n    set Preprocessing(streamPreprocessing){\n        this.streamPreprocessing = streamPreprocessing;\n    }\n\n    \n\n    setByConfig(pipelineConfig){\n        if(super.setByConfig){\n            super.setByConfig(pipelineConfig);\n        }\n        const { Preprocessing } = pipelineConfig.Dataset;\n        this.Logger.groupBegin('preprocessing');\n        if(this.DataSource && Preprocessing){\n            const { SampleTransformer, LabelTransformer } = Preprocessing;\n            this.Preprocessing.SampleTransformer = SampleTransformer;\n            this.Preprocessing.LabelTransformer = LabelTransformer;\n            this.Preprocessing.setDataHandler();\n            pipelineConfig.TrainDataGenerator = this.Preprocessing.TrainDataGenerator;\n            pipelineConfig.TestDataGenerator = this.Preprocessing.TestDataGenerator;\n        }\n        this.Logger.groupEnd();\n        return pipelineConfig;\n    }\n};\n\nexport default PreprocessingMixins;","const ColorTransformingMixins = (PreprocessingClass) => class extends PreprocessingClass{\n    \n    colorTransform(tranformFn, sampleBuffer, channelSize){\n        const R = this.R;\n        return R.flatten(R.map(tranformFn, R.splitEvery(channelSize, sampleBuffer)));\n    }\n    /**\n     * Transform color image to black on white image. This function also reduce chanel to 1.\n     * @param { Array|Buffer } sampleBuffer\n     * @param { Number } channelSize\n     * @return { Array } image data after transform\n     */\n    blackWhiteTransform(sampleBuffer, channelSize){\n        const BlackWhiteFn = (pixel)=>{\n            let pixelValue = (pixel[0] + pixel[1] +pixel[2])/3;\n            return ~~pixelValue;\n        };\n        return this.colorTransform(BlackWhiteFn, sampleBuffer, channelSize);\n    }\n};\n\nexport default ColorTransformingMixins;","const ImageSplittingMixins = (PreprocessingClass) => class extends PreprocessingClass{\n    /**\n     * Split image into sub images based on split size\n     * @param { Array|Buffer } sampleBuffer - original image\n     * @param { Number } splitSize - positive number\n     * @returns { Array } - array of sub image\n     */\n    imageSplit(sampleBuffer, splitSize){\n        return this.R.splitEvery(splitSize, sampleBuffer);\n    }\n};\n\nexport default ImageSplittingMixins;","import { Functor as BaseFunctor } from 'causal-net.core';\nimport { platform } from 'causal-net.utils';\nimport { ColorTransformingMixins, ImageSplittingMixins } from './Image/index';\n\n/**\n * This ImagePreprocessing provide methods for preprocessing image data\n * { MixWith: [\n *         ColorTransformingMixins, ImageSplittingMixins\n *     ] }\n * @class ImagePreprocessing\n * @extends BaseFunctor\n * @example\n * [EXAMPLE ../examples/imagePreprocessing.babel.node.js]\n */\nclass ImagePreprocessing extends platform.mixWith(BaseFunctor, [\n        ColorTransformingMixins, \n        ImageSplittingMixins ]){\n    constructor(){\n        super();\n    }\n}\n\nexport default new ImagePreprocessing;","const TokenTransformingMixins = (PreprocessingClass) => class extends PreprocessingClass{\n    /**\n     * tokenized sentence\n     * @param { String } sentence - array of string sentence\n     * @returns { Array } array of tokenized sentences\n     */\n    tokenize(sentence){\n        const R = this.R, Tokenizer = this.tokenizer;\n        return Tokenizer.tokenize(sentence);\n    }\n    /**\n     * Remove bad words from tokens\n     * @param { Array } tokens - array of string token\n     * @param { Array } badWordList - Array of bad words\n     * @returns { Array } tokens without bad words\n     */\n    badWordsFilter(tokens, badWordList){\n        const R = this.R;\n        return R.filter((token)=>R.not(R.find(R.equals(token))(badWordList)), tokens);\n    }\n    /**\n     * Count number of apperance of each token in the token list\n     * @param { Array } tokens - array of string tokens\n     * @param { Object } [freqCount={}] - objec or previous wordFreqCount, empty object if not provided\n     * @returns { Object } - json object with token as key and counting number as corresponding value\n     */\n    wordFreqCount(tokens, freqCount={}){\n        const R = this.R;\n        const UpdateFreq = (freqCount, token)=>{\n            if(freqCount[token] === undefined){\n                freqCount[token] = 1;\n            }\n            else{\n                freqCount[token] += 1;\n            }\n            return freqCount;\n        };\n        return R.reduce(UpdateFreq, freqCount, tokens);\n    }\n    /**\n     * Remove duplicated tokens\n     * @param { Array } tokens - array of string token\n     * @returns\n     */\n    wordDuplicateRemove(tokens){\n        const R = this.R;\n        return R.uniq(tokens);\n    }\n};\nexport default TokenTransformingMixins;","import { Functor as BaseFunctor } from 'causal-net.core';\nimport { platform } from 'causal-net.utils';\nimport { TokenTransformingMixins } from './NLP/index';\n/**\n * This NLPPreprocessing class provide methods for preprocessing text and output valid tokens.\n * { MixWith:\n *     [ TokenTransformingMixins ]) }\n * @class NLPPreprocessing\n * @extends BaseFunctor\n * @example\n * [!EXAMPLE ../examples/nlpPreprocessing.babel.node.js]\n */\n\nclass NLPPreprocessing extends platform.mixWith(BaseFunctor, \n    [ TokenTransformingMixins ]){\n    constructor(){\n        super();\n    }\n    /**\n     * This method is used in case tokenizer requires data setup.\n     * @param { Url|FilePath } configLink\n     * @memberof NLPPreprocessing\n     */\n    connect(configLink){\n        this.tokenizer.connect(configLink);\n    }\n    /**\n     * Get tokenizer\n     *\n     * @memberof NLPPreprocessing\n     */\n    get Tokenizer(){\n        if(!this.tokenizer){\n            throw Error('tokenizer is not set');\n        }\n        return this.tokenizer;\n    }\n    /**\n     * Set tokenizer\n     * @param { Object } tokenizer - tokenizer object\n     * @memberof NLPPreprocessing\n     */\n    set Tokenizer(tokenizer){\n        this.tokenizer = tokenizer;\n    }\n}\n\nexport default new NLPPreprocessing;","import { Functor as BaseFunctor } from 'causal-net.core';\nimport { platform } from 'causal-net.utils';\nimport { ItemNormalizing, NullItemReplace } from './Tabular/index';\nclass TabularPreprocessing extends platform.mixWith(BaseFunctor, \n    []){\n    constructor(){\n        super();\n    }\n}\n\nexport default new TabularPreprocessing;","/**\n * This TokenizerEN is a simple implementation for English tokenizer\n * @todo enhance it with entities and built-in vocab\n * @experiment\n * @class TokenizerEN\n */\nclass TokenizerEN{\n    constructor(){\n    }\n    connect(configureLink){\n        console.log('This simple English tokenizer not requires advance configure');\n    }\n    tokenize(text){\n        const Re = /[\\s.\"'/\\|;:()\\[\\]\\@\\#\\$\\&]/g;\n        return text.split(Re).filter(token=>token!=='');\n    }\n}\nexport default new TokenizerEN();","export { default as causalNetPreprocessingStream } from './causalNetPreprocessingStream';\nexport { default as PreprocessingMixins} from './preprocessing.mixins';\n\nexport { default as imagePreprocessing } from './imagePreprocessing';\nexport { default as nlpPreprocessing } from './nlpPreprocessing';\nexport { default as tabularPreprocessing } from './tabularPreprocessing';\n\nexport { default as tokenizerEN } from './tokenizer.en';"],"sourceRoot":""}